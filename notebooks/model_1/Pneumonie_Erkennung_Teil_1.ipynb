{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Pneumonia Detection Part 1\n",
        "# This algorithm scans lung X-rays to differentiate whether they\n",
        "# are infected with pneumonia or not.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#import shap\n",
        "\n",
        "def collect_images(path,target):\n",
        "    images_list = []\n",
        "    target_list = []\n",
        "    target = target\n",
        "    for r, d, f in os.walk(path):\n",
        "        for file in f:\n",
        "            if ('.jpeg' in file):\n",
        "                images_list.append(os.path.join(r, file))\n",
        "                target_list.append(target)\n",
        "\n",
        "    features =np.transpose([np.array(images_list)])\n",
        "    labels = np.transpose([np.array(target_list)])\n",
        "\n",
        "    return features,labels\n",
        "\n",
        "def convert_img(img_path):\n",
        "    # loads RGB image as PIL.Image.Image type\n",
        "    img = image.load_img(img_path, target_size=(125, 125))\n",
        "    # convert PIL.Image.Image type to 3D tensor with shape (40, 40, 3)\n",
        "    x = image.img_to_array(img)\n",
        "    # convert 3D tensor to 4D tensor with shape (1, 40, 40, 3) and return 4D tensor\n",
        "    exp_array = np.expand_dims(x, axis=0)\n",
        "    return exp_array.astype('float32')/255\n",
        "\n",
        "def paths_to_images(images):\n",
        "    list_of_images = [convert_img(img_path) for img_path in tqdm(images)]\n",
        "    return np.vstack(list_of_images)\n",
        "\n",
        "def find_smallest_dimension():\n",
        "    #high unrealistic initial values\n",
        "    width = 10000\n",
        "    height = 10000\n",
        "    for i in range(len(features)):\n",
        "        path = features[i,0]\n",
        "        img = image.load_img(path)\n",
        "        tmp_width, tmp_height = img.size\n",
        "\n",
        "        if tmp_width < width:\n",
        "            width = tmp_width\n",
        "        if tmp_height < height:\n",
        "            height = tmp_height\n",
        "\n",
        "    print(\"Smallest width: %d: Smallest height: %d\" %(width,height))\n",
        "\n",
        "# Montar Google Drive (opcional, si tus datos están en Google Drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta a la carpeta principal del dataset\n",
        "#base_dir = '/content/drive/My Drive/data2'  # Asegúrate de cambiar esto a la ruta correcta\n",
        "\n",
        "normal_path = \"/content/drive/My Drive/data2/not_infected\"\n",
        "ill_path = \"/content/drive/My Drive/data2/infected\"\n",
        "\n",
        "normal_X,  normal_Y= collect_images(normal_path,target=0)\n",
        "ill_X,ill_Y = collect_images(ill_path,target=1)\n",
        "\n",
        "features = np.concatenate((normal_X,ill_X),axis=0)\n",
        "labels = np.concatenate((normal_Y,ill_Y),axis=0)\n",
        "\n",
        "find_smallest_dimension()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
        "\n",
        "train_tensor = paths_to_images(X_train.flatten())\n",
        "test_tensor = paths_to_images(X_test.flatten())\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(16,kernel_size=2,strides=1,padding='same', activation='relu', input_shape=train_tensor.shape[1:]),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2),\n",
        "        tf.keras.layers.Conv2D(32,kernel_size=2,strides=1,padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2),\n",
        "        tf.keras.layers.Conv2D(64,kernel_size=2,strides=1,padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(500, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[tf.keras.metrics.Recall(name='recall'), 'accuracy'])\n",
        "\n",
        "early_stopping_monitor = EarlyStopping(\n",
        "    monitor='loss',\n",
        "    min_delta=0,\n",
        "    patience=10,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(train_tensor,\n",
        "                    y_train.flatten(),\n",
        "                    callbacks=[early_stopping_monitor],\n",
        "                    epochs=100,\n",
        "                    verbose=2)\n",
        "\n",
        "eval_results = model.evaluate(test_tensor, y_test.flatten(), verbose=2)\n",
        "\n",
        "loss = history.history['loss']\n",
        "rec = history.history['recall']\n",
        "acc = history.history['accuracy']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "fig_SI = plt.figure()\n",
        "\n",
        "ax1_SI = fig_SI.add_subplot(111)\n",
        "\n",
        "ax1_SI.plot(epochs, loss, 'g.', label='Training loss')\n",
        "ax1_SI.plot(epochs, rec, 'b.', label='recall')\n",
        "ax1_SI.plot(epochs, acc, 'r.', label='accuracy')\n",
        "\n",
        "fig_SI.suptitle('Training loss and accuracy')\n",
        "ax1_SI.set_xlabel('Epochs')\n",
        "ax1_SI.legend()\n",
        "fig_SI.show()\n",
        "\n",
        "def visualize_confusion(conf_matrix, name):\n",
        "    # normalize values\n",
        "    normalized_conf_matrix = conf_matrix / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    conf_figure, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "\n",
        "    ax.matshow(normalized_conf_matrix, cmap=plt.cm.BuPu)\n",
        "    for i in range(normalized_conf_matrix.shape[0]):\n",
        "        for j in range(normalized_conf_matrix.shape[1]):\n",
        "            ax.text(x=j, y=i, s=round(normalized_conf_matrix[i, j], 2), va='center', ha='center', size='xx-large')\n",
        "\n",
        "    conf_figure.suptitle('Confusion matrix')\n",
        "    tick_marks = np.arange(len(conf_matrix))\n",
        "    ax.set_xticks(tick_marks)\n",
        "    ax.set_xticklabels(['no_pneumonia', 'pneumonia'])\n",
        "    ax.set_yticklabels(['no_pneumonia', 'pneumonia'])\n",
        "    ax.set_yticks(tick_marks)\n",
        "    ax.set_ylabel('True label')\n",
        "    ax.set_xlabel('Predicted label')\n",
        "\n",
        "    filename = name + '_Confusion_matrix'\n",
        "\n",
        "    conf_figure.savefig(filename, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return normalized_conf_matrix[1, 1]\n",
        "\n",
        "prediction = model.predict(test_tensor)\n",
        "rounded_prediction = tf.math.round(prediction)\n",
        "# create a confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true=y_test.flatten(), y_pred=rounded_prediction)\n",
        "keras_name = 'pneumonia'\n",
        "tpr = visualize_confusion(conf_matrix,keras_name)\n",
        "\n",
        "print('The accuracy is: ' +'{:.1%}'.format(eval_results[2]))\n",
        "print('The true positive rate is: ' +'{:.1%}'.format(tpr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAia0lglVP3p",
        "outputId": "c4000e41-5747-4f80-f974-2d99a0039d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Smallest width: 384: Smallest height: 127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3923/3923 [00:53<00:00, 73.79it/s]\n",
            "100%|██████████| 1933/1933 [00:27<00:00, 71.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 125, 125, 16)      208       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 62, 62, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 62, 62, 32)        2080      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 31, 31, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 31, 31, 64)        8256      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 15, 15, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 14400)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 500)               7200500   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 500)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 501       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7211545 (27.51 MB)\n",
            "Trainable params: 7211545 (27.51 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "123/123 - 52s - loss: 0.3126 - recall: 0.9540 - accuracy: 0.8708 - 52s/epoch - 422ms/step\n",
            "Epoch 2/100\n",
            "123/123 - 48s - loss: 0.1623 - recall: 0.9668 - accuracy: 0.9449 - 48s/epoch - 390ms/step\n",
            "Epoch 3/100\n",
            "123/123 - 52s - loss: 0.1332 - recall: 0.9678 - accuracy: 0.9495 - 52s/epoch - 421ms/step\n",
            "Epoch 4/100\n",
            "123/123 - 49s - loss: 0.1283 - recall: 0.9706 - accuracy: 0.9513 - 49s/epoch - 400ms/step\n",
            "Epoch 5/100\n",
            "123/123 - 50s - loss: 0.1027 - recall: 0.9786 - accuracy: 0.9625 - 50s/epoch - 405ms/step\n",
            "Epoch 6/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# guardar modelo\n",
        "\n",
        "import os\n",
        "\n",
        "currentDirectory = os.getcwd()  # Obtiene el directorio actual\n",
        "model_name = 'model_01'\n",
        "model_path = model_name + \".keras\"\n",
        "model.save(model_path)\n",
        "model_path_for_tiny = os.path.join(currentDirectory, model_path)"
      ],
      "metadata": {
        "id": "-lLPzKXmAwfn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}